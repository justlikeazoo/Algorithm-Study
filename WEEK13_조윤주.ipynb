{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진 분류 예측\n",
    "Data Science London + Scikit-learn\n",
    "\n",
    "- Data Science London은 Scikit-learn에서 모임 주최중\n",
    "- Scikit-learn을 활용한 분류 능력에 대한 사례를 연습하기 위함\n",
    "    - Scikit-learn(sklearn)은 NumPy, SciPy 및 Cython의 도움을 받아 Python으로 작성된 확립된 오픈 소스 기계 학습 라이브러리\n",
    "    - Scikit-learn은 매우 사용자 친화적이고 일관된 API를 갖추고 있으며 광범위한 문서를 제공\n",
    "    -  엄격한 코딩 표준과 높은 테스트 범위로 인해 구현 품질이 높음\n",
    "    - sklearn 뒤에는 매우 활동적인 커뮤니티가 있어 꾸준한 라이브러리 개선\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science London + Scikit-learn는 어떤 대회인가?\n",
    "1. 데이터 세트\n",
    "레이블이 지정된 훈련 데이터 세트와 레이블이 없는 테스트 데이터 세트로 구성\n",
    "훈련 데이터를 사용해 모델을 학습 시키고, 테스트 데이터에 대한 예측 생성해야 함\n",
    "\n",
    "2. 목표\n",
    "주어진 데이터를 바탕으로 최적의 ML 모델을 구축하여 테스트 데이터에 대한 예측을 하는 것\n",
    "\n",
    "3. 도구\n",
    "Scikit-learn 같은 Python 라이브러리가 주로 사용됩니다. 이 라이브러리는 분류, 회귀, 군집화 등 다양한 머신러닝 기법을 지원\n",
    "\n",
    "4. 참가자\n",
    "이 대회는 데이터 과학과 머신러닝 분야의 초보자들에게 인기가 있으며, 실제 프로젝트에 적용할 수 있는 경험을 쌓을 수 있는 좋은 기회를 제공\n",
    "\n",
    "5. 평가 기준\n",
    "평가 방법은 대회마다 다를 수 있으나, 일반적으로 정확도, F1 점수, ROC-AUC 점수 등의 메트릭을 사용하여 모델의 성능을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터(x_train), 훈련 레이블(y_train), 테스트 데이터(x_test)를 CSV 파일에서 불러오기\n",
    "# 데이터는 NumPy 배열로 변환되고, y_train은 1차원 배열로 변형\n",
    "\n",
    "x_train = pd.read_csv('C:/Users/jyjj0/OneDrive/바탕 화면/Algorithm Study/WEEK13/train.csv')\n",
    "y_train = pd.read_csv('C:/Users/jyjj0/OneDrive/바탕 화면/Algorithm Study/WEEK13/trainLabels.csv')\n",
    "x_test = pd.read_csv('C:/Users/jyjj0/OneDrive/바탕 화면/Algorithm Study/WEEK13/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 결합하여 x_all을 생성\n",
    "# 이는 Gaussian Mixture Model(GMM)을 적용하기 위한 전처리 단계\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_x Shape: (999, 40) ,training_y Shape: (999,) ,testing_x Shape: (8999, 40)\n"
     ]
    }
   ],
   "source": [
    "#다양한 구성 요소 수(n_components)와 공분산 유형(cv_types)에 대해 GMM을 적용\n",
    "#Akaike Information Criterion(AIC)를 사용하여 최적의 모델을 선택\n",
    "#선택된 최적의 GMM 모델로 x_train과 x_test 데이터를 변환\n",
    "#데이터 크기 출력:변환된 데이터의 차원(행과 열의 수)을 출력\n",
    "\n",
    "\n",
    "print('training_x Shape:', x_train.shape, ',training_y Shape:', y_train.shape, ',testing_x Shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_all shape: (9998, 40)\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors(KNN) 분류기와 Random Forest 분류기를 초기화\n",
    "# GridSearchCV를 사용하여 각 모델에 대한 최적의 매개변수를 찾음 -> 여기서는 매개변수 그리드가 비어 있으므로 기본 매개변수 사용\n",
    "#훈련 및 테스트 데이터 결합:np.r_을 사용하여 훈련 데이터와 테스트 데이터를 결합\n",
    "#결합된 데이터 x_all의 크기를 출력\n",
    "\n",
    "x_all = np.r_[x_train, x_test]\n",
    "print('x_all shape:', x_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gaussian Mixture Model to transform features \n",
    "\n",
    "Gaussian Mixture Model(GMM) 적용\n",
    "\n",
    "\n",
    "GMM 구성 요소(n_components) 및 공분산 유형(cv_types)에 대해 모델을 학습시킴\n",
    "\n",
    "각 모델의 AIC 값을 계산하여 최적의 GMM 모델을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "\n",
    "best_gmm.fit(x_all)\n",
    "x_train = best_gmm.predict_proba(x_train)\n",
    "x_test = best_gmm.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator KNN: KNeighborsClassifier() Best Score 0.995995995995996\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters for KNN\n",
    "grid_search_knn = GridSearchCV(knn, param_grid={}, cv=10, scoring='accuracy').fit(x_train, y_train)\n",
    "print('best estimator KNN:', grid_search_knn.best_estimator_, 'Best Score', grid_search_knn.best_estimator_.score(x_train, y_train))\n",
    "knn_best = grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화된 KNN과 랜덤 포레스트 모델을 훈련 데이터에 적합시킴\n",
    "\n",
    "테스트 데이터에 대해 예측을 수행하고 처음 10개의 예측 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV 1/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 2/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 3/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 4/10] END .................................., score=0.990 total time=   0.0s\n",
      "[CV 5/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 6/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 7/10] END .................................., score=0.990 total time=   0.0s\n",
      "[CV 8/10] END .................................., score=1.000 total time=   0.0s\n",
      "[CV 9/10] END .................................., score=0.980 total time=   0.0s\n",
      "[CV 10/10] END ................................., score=1.000 total time=   0.0s\n",
      "best estimator RandomForest: RandomForestClassifier() Best Score 0.997997997997998\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters for Random Forest\n",
    "grid_search_rf = GridSearchCV(rf, param_grid={}, verbose=3, scoring='accuracy', cv=10).fit(x_train, y_train)\n",
    "print('best estimator RandomForest:', grid_search_rf.best_estimator_, 'Best Score', grid_search_rf.best_estimator_.score(x_train, y_train))\n",
    "rf_best = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 1]\n",
      "[0 1 0 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 최적화된 KNN 모델과 rf모델을 각각 훈련 데이터에 적합시키고, 테스트 데이터에 대한 예측을 수행함. 예측 결과의 처음 10개를 출력\n",
    "knn_best.fit(x_train, y_train)\n",
    "print(knn_best.predict(x_test)[:10])\n",
    "\n",
    "rf_best.fit(x_train, y_train)\n",
    "print(rf_best.predict(x_test)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for KNN: 0.9960000000000001\n",
      "Score for Random Forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증을 통한 모델 평가\n",
    "print('Score for KNN:', cross_val_score(knn_best, x_train, y_train, cv=10, scoring='accuracy').mean())\n",
    "print('Score for Random Forest:', cross_val_score(rf_best, x_train, y_train, cv=10, scoring='accuracy').max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 검증을 사용하여 KNN과 랜덤 포레스트 모델의 정확도를 평가\n",
    "\n",
    "여기서는 평균 정확도와 최대 정확도를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions to CSV\n",
    "rf_best_pred = pd.DataFrame(rf_best.predict(x_test))\n",
    "rf_best_pred.index += 1\n",
    "rf_best_pred.to_csv('Submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " GMM을 사용하여 데이터의 특성을 변환하고, KNN과 랜덤 포레스트 분류기를 통해 분류 문제를 해결하는 전략을 보여줌\n",
    " \n",
    " 코드의 효율성과 정확도는 데이터의 특성과 매개변수 설정에 크게 의존함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
